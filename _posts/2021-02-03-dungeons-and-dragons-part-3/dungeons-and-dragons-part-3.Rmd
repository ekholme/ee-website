---
title: "Dungeons and Dragons - Part 3"
description: |
  Grouping D&D monsters using latent profile analysis.
author:
  - name: EE
    url: https://www.ericekholm.com/
date: 02-03-2021
output:
  distill::distill_article:
    self_contained: false
draft: true
---

This post is the next installment in a mini-series I'm doing where I explore Dungeons and Dragons (D&D) data. In the [first post](https://www.ericekholm.com/posts/2021-01-11-dungeons-and-dragons-part-1/), I showed how to wrangle JSON data from a [D&D API](https://www.dnd5eapi.co/), and in the [second post](https://www.ericekholm.com/posts/2021-01-11-dungeons-and-dragons-part-2/), I explored monster statistics.

In this post, I'm going to use latent profile analysis (LPA) and monsters' ability scores to try to classify monsters into different "classes." For instance, we might suspect that there is a "class" of up-in-your-face monsters that have high strength and constitution but low intelligence, whereas there may be another class of spell casters that has high intelligence and charisma but low strength and constitution. LPA gives us a framework to estimate how many of these classes exist as well as which monsters fall into which classes.

*Note: I'm probably going to use the terms profile, class, group, and cluster somewhat interchangeably throughout this post (because I'm undisciplined), so just as a warning ahead of time -- these all mean pretty much the same thing.*

Before getting into the meat of this post, I want to give a shoutout to the excellent [`{tidyLPA]}` package](https://cran.r-project.org/package=tidyLPA), which provides some functions to make doing LPA easier.

So let's get into it, then.

# Setup

First, I'll load some packages that are useful here. Notably, we'll load `{tidyLPA}` for doing the actual LPA. This calls the `{mclust}` package to fit the model, and I could use `{mclust}` directly, but `{tidyLPA}` makes the process somewhat more convenient. I'm also going to get a tibble of monster data in this setup chunk. I walk through this process in my first D&D blog post, so if you're curious about that, feel free to check out that post.

```{r setup, echo = TRUE, results = "hide", warning = FALSE, message = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

library(tidyverse)
library(eemisc) #ggplot theme
library(jsonlite) #work with json data
library(tidyLPA)
library(harrypotter) #colors
library(tidytext) #for reorder_within function
library(gt) #make tables

herm <- harrypotter::hp(n = 1, option = "HermioneGranger")

opts <- options(
  ggplot2.discrete.fill = list(
    harrypotter::hp(n = 3, option = "HermioneGranger"),
    harrypotter::hp(n = 7, option = "Always")
  )
)

theme_set(theme_ee())

dnd_base <- "https://www.dnd5eapi.co/api/monsters/"

#getting data from api -- see 1st d&d post
#for process explanation

fetch_monster <- function(monster) {
  dnd_url <- "https://www.dnd5eapi.co/api/monsters/"
  
  ret <- fromJSON(paste0(dnd_url, monster)) %>%
    enframe() %>%
    pivot_wider(names_from = name,
                values_from = value)
  
  return(ret)
}

compare_lens <- function(x, size = 1) {
  all(map_lgl(x, ~length(unlist(.x)) == size))
}
cond_unlist <- function(x) {
  if (compare_lens(x) == TRUE) {
    unlist(x)
  } else {
    x
  }
}

mons <- fromJSON(dnd_base)$results %>%
  pull(index)

monster_lists <- purrr::map(mons, fetch_monster)

mons_bind <- bind_rows(monster_lists)

mons_df <- mons_bind %>%
  mutate(across(.cols = everything(), ~cond_unlist(x = .x)))

```


# What is LPA?

Before getting into actually fitting any models, I want to do a very brief and minimally technical toe-dip into what LPA actually is. Like I mentioned just above, LPA is an approach for estimating groups of people/things/monsters/whatever. You might think of it as akin to principal components analysis (PCA) or exploratory factor analysis (EFA), except instead of grouping variables together, LPA groups observations together. LPA is itself a special type of mixture model, and the basic idea of mixture modeling is that there are *k* latent (underlying) subpopulations (groups) within a population, where the number of groups *k* is something the researcher/analyst should determine either empirically or using past research.

If you're familiar with k-means clustering, this probably sounds very similar. And it pretty much is. The main difference between LPA and k-means is that, since LPA estimates distributions for each subpopulation in the model, we get the probability that each observation belongs to each class, e.g. Monster 1 might have a 99% probability of belonging to class 1, whereas Monster 2 might have an 80% probability of belonging to class 1. And depending on how you intend to use your model, this information might be useful. Another potentially useful difference is that LPA provides a number of fit statistics that (at least as far as I know) aren't available for k-means clustering.

As with EFA (and other latent-variable models), the assumption of LPA is that the latent (unobserved) factor "causes" (I'm using the term loosely here) observed scores on the indicator variables. So, to refer back to my initial hypothetical example, a monster being a spell caster (the unobserved class) causes it to have high intelligence, low strength, etc. rather than the inverse. This is a worthwhile distinction to keep in mind, since it has implications for how the model is fit.

There are some other, more practical considerations regarding LPA that I'll bring up once we get into the modeling, but this is enough background to get started.

# Binning Monsters

RESUME HERE.

```{r cr_distrib}
mons_df %>%
  ggplot(aes(x = challenge_rating)) +
  geom_histogram(alpha = .8, fill = herm, color = herm) +
  labs(
    title = "Distribution of Monster Challenge Rating"
  )
```


```{r bin_monsters}
#divide monsters into hexiles
mons_bin <- mons_df %>%
  mutate(cr_bin = ntile(x = challenge_rating, n = 6)) 

mons_bin %>%
  ggplot(aes(x = challenge_rating, y = cr_bin, color = cr_bin)) +
  geom_jitter() +
  scale_color_hp() +
  labs(
    y = "Challenge Bin",
    x = "Challenge Rating",
    title = "Binned CR by Actual CR"
  ) +
  theme(
    legend.position = "none"
  )
```

```{r mean_ctr}
ab_scores <- c("strength", "dexterity", "constitution", "intelligence", "wisdom", "charisma")

mons_bin <- mons_bin %>%
  group_by(cr_bin) %>%
  mutate(across(.cols = ab_scores, .fns = mean, .names = "{.col}_bin_mean")) %>%
  ungroup()


ab_scores_grp <- str_replace_all(ab_scores, "$", "_bin_mean")


mons_centered <- map2_dfc(mons_bin[, ab_scores], mons_bin[, ab_scores_grp],
         ~.x - .y) %>%
  rename_with(.fn = ~str_replace_all(.x, "$", "_centered")) %>%
  bind_cols(mons_bin, .) %>%
  select(name, ends_with("centered"))
```


```{r}
set.seed(0408)
lpa_fits <- mons_centered %>%
  estimate_profiles(1:5,
                    variances = c("equal", "varying"),
                    covariances = c("zero", "zero"),
                    select_vars = str_subset(names(mons_centered), "centered"))
```


```{r}
mods <- names(lpa_fits)
#recall that model 1 corresponds to equal variances; model 2 corresponds to varying variances

#getting some fit indices
bics <- map_dbl(1:10, ~pluck(lpa_fits, .x, "fit", "BIC"))
entrops <- map_dbl(1:10, ~pluck(lpa_fits, .x, "fit", "Entropy"))

fit_indices <- bind_cols(mods, bics, entrops) %>%
  set_names(c("model", "bic", "entrop")) %>%
  pivot_longer(cols = c("bic", "entrop"),
               names_to = "metric",
               values_to = "val")

lpa_fits %>%
  compare_solutions()

```


```{r plot_fits}
fit_indices %>%
  ggplot(aes(x = val, y = reorder_within(model, val, metric), fill = metric)) +
  geom_col() +
  geom_text(aes(label = if_else(val > 1, round(val, 0), round(val, 3)), x = val - .01), hjust = 1, color = "white") +
  facet_wrap(vars(metric), scales = "free") +
  scale_y_reordered() +
  labs(
    y = "Model",
    x = "Value",
    title = "Selected Fit Indices"
  ) +
  theme(
    legend.position = "none"
  )
```

```{r}
prof_estimates <- get_estimates(lpa_fits) %>%
  filter(Model == 2,
         Classes == 5)

prof_estimates %>%
  filter(Category == "Means") %>%
  mutate(Class = str_replace_all(Class, "^", "Profile "),
         Parameter = str_remove_all(Parameter, "_centered")) %>%
  ggplot(aes(x = Estimate, y = Parameter)) +
  geom_col(aes(fill = if_else(Estimate > 0, TRUE, FALSE))) +
  facet_wrap(vars(Class)) +
  labs(
    y = NULL,
    x = "CR-Centered Ability Score",
    title = "Ability Score Means by Profile",
    caption = "5 profiles, varying variances"
  ) +
  theme(
    legend.position = "none"
  )

```



```{r}
class_assigns <- get_data(lpa_fits) %>%
  filter(model_number == 2,
         classes_number == 5) %>%
  group_by(id) %>%
  filter(Probability == max(Probability)) %>%
  ungroup() %>%
  select(name, Class, Probability)

class_assigns %>%
  count(Class)
#this feels reasonable -- no class here is super sparse
```

```{r example_mons}
set.seed(0409)
class_assigns %>%
  group_by(Class) %>%
  sample_n(size = 1) %>%
  ungroup() %>%
  select(Class, name, Probability) %>%
  gt() %>%
  tab_header(
    title = "Example Monster for Each Class"
  ) %>%
  cols_label(
    Class = "Esimated Class",
    name = "Monster",
    Probability = "Estimated Class Prob"
  ) %>%
  fmt_percent(
    columns = vars(Probability)
  )
```


That's it for now.




